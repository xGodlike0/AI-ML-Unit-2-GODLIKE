{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # DATA CORRELATION\n",
    "\n",
    " Comprendere il concetto di correlazione tra dati è fondamentale in Machine Learning poiché la correlazione può influenzare direttamente la qualità dei modelli di Machine Learning e le decisioni basate su di essi.\n",
    "\n",
    "La correlazione tra dati si riferisce alla relazione tra due o più variabili in un dataset. Se due variabili sono correlate, significa che c'è una relazione tra di esse, e che il valore di una variabile può influenzare il valore dell'altra variabile.\n",
    "\n",
    "Quando si lavora con i dati di Machine Learning, la correlazione tra le variabili può influire sulla capacità del modello di fare previsioni accurate. Ad esempio, se due variabili sono fortemente correlate, può essere necessario considerarle entrambe quando si costruisce un modello. D'altra parte, se due variabili non sono correlate, può non essere necessario considerarle entrambe.\n",
    "\n",
    "Inoltre, la correlazione tra i dati può anche influire sulla scelta degli algoritmi di Machine Learning da utilizzare. Alcuni algoritmi funzionano meglio con dati altamente correlati, mentre altri funzionano meglio con dati poco correlati.\n",
    "\n",
    "In generale, comprendere la correlazione tra i dati è essenziale per garantire che i modelli di Machine Learning siano accurati e affidabili, e che le decisioni basate su di essi siano appropriate e ben informate.\n",
    "\n",
    " <img width=\"75%\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/1920px-Correlation_examples2.svg.png\" />\n",
    "\n",
    " <img src=\"https://wtmaths.com/P384_z1.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEASURING CORRELATION\n",
    "\n",
    "Esistono diversi modi per misurare la correlazione tra i dati, ma i due metodi più comuni sono il coefficiente di correlazione di Pearson e il coefficiente di correlazione di Spearman.\n",
    "\n",
    "Il coefficiente di correlazione di Pearson misura la relazione lineare tra due variabili continue. Il coefficiente può variare da -1 a 1, dove -1 rappresenta una forte correlazione negativa, 0 rappresenta l'assenza di correlazione e 1 rappresenta una forte correlazione positiva.\n",
    "\n",
    "Il coefficiente di correlazione di Spearman, d'altra parte, è utilizzato per misurare la relazione tra due variabili ordinali o continue non normali. Questo coefficiente utilizza invece il grado di classifica delle variabili in modo da trovare la relazione monotona tra due variabili. Il coefficiente di correlazione di Spearman può variare da -1 a 1, dove -1 rappresenta una forte correlazione negativa, 0 rappresenta l'assenza di correlazione e 1 rappresenta una forte correlazione positiva.\n",
    "\n",
    "Per entrambi i coefficienti, i valori vicini a 0 indicano una bassa correlazione, mentre i valori vicini a 1 o -1 indicano una forte correlazione.\n",
    "\n",
    "In generale, il coefficiente di correlazione di Pearson è utilizzato per variabili continue normalmente distribuite, mentre il coefficiente di correlazione di Spearman è utilizzato per variabili ordinali o continue non normali. Tuttavia, l'uso di un coefficiente di correlazione dipende dalle specifiche caratteristiche dei dati e delle variabili coinvolte.\n",
    "\n",
    "<mark style=\"background-color: yellow;\">Quando il coefficiente di correlazione di Pearson è pari a -1, indica una perfetta relazione lineare negativa tra due variabili. Ciò significa che all'aumentare del valore di una variabile, il valore dell'altra variabile diminuisce di una quantità proporzionale, risultando in una linea retta con una pendenza negativa quando le due variabili sono rappresentate in un diagramma di dispersione.\n",
    "\n",
    "In altre parole, quando il coefficiente di correlazione di Pearson è pari a -1, le due variabili sono perfettamente negative correlate, il che significa che si muovono in direzioni opposte in modo lineare. Ciò implica che se una variabile aumenta, l'altra variabile diminuirà sempre, e viceversa.\n",
    "\n",
    "Ad esempio, se consideriamo la relazione tra la temperatura in Celsius e la temperatura in Fahrenheit, sappiamo che hanno una perfetta correlazione negativa, perché all'aumentare di una scala di temperatura, l'altra scala di temperatura diminuisce in modo lineare. Pertanto, il coefficiente di correlazione di Pearson tra queste due variabili sarebbe -1.</mark>\n",
    "\n",
    "<img width='70%' src=\"https://upload.wikimedia.org/wikipedia/commons/3/34/Correlation_coefficient.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of coordinates matrix:\n",
    "\n",
    "| X \t| Y |\n",
    "| ----------- | ----------- |\n",
    "| 0.1 |\t45\n",
    "| 0.1 |\t65\n",
    "| 0.2 |\t28\n",
    "| 0.3 |\t76\n",
    "| 0.5 |\t55\n",
    "| 0.6 |\t48\n",
    "| 0.9 |\t64\n",
    "| 1.1 |\t41\n",
    "| 1.5 |\t30\n",
    "| 1.8 |\t52\n",
    "| 1.8 |\t75\n",
    "| 1.9 |\t35\n",
    "| 2.1 |\t42\n",
    "| 2.2 |\t65\n",
    "| 3.0 |\t30\n",
    "| 3.6 |\t71"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEARSON'S CORRELATION COEFFICIENT\n",
    "\n",
    "https://www.youtube.com/watch?v=xZ_z8KWkhXE&list=LL&index=6&t=1034s\n",
    "\n",
    "### Recall that:\n",
    "\n",
    "<mark style=\"background-color: yellow;\">La covarianza di due serie è una misura statistica che indica la relazione lineare tra le due serie. La covarianza è una misura della variabilità congiunta delle due serie: se le due serie variano insieme in modo simile, la covarianza sarà positiva; se invece variano in modo opposto, la covarianza sarà negativa; se non c'è alcuna relazione lineare tra le due serie, la covarianza sarà zero.</mark>\n",
    "\n",
    "Formalmente, la covarianza tra due serie X e Y è data dalla seguente formula:\n",
    "\n",
    "$$\\operatorname{cov}(X,Y) = \\frac{\\sum\\limits_{i=1}^{n} (X_i - \\bar{X}) (Y_i - \\bar{Y})}{n-1}$$\n",
    "\n",
    "dove $X_i$ e $Y_i$ sono i valori osservati delle due serie, $\\bar{X}$ e $\\bar{Y}$ sono le loro medie campionarie e $n$ è il numero di osservazioni.\n",
    "\n",
    "Se la covarianza è positiva, significa che le due serie sono correlate positivamente: cioè, quando il valore di una serie aumenta, anche il valore dell'altra serie tende ad aumentare. Se la covarianza è negativa, significa che le due serie sono correlate negativamente: cioè, quando il valore di una serie aumenta, il valore dell'altra serie tende a diminuire. Se la covarianza è zero, significa che le due serie non sono correlate linearmente.\n",
    "\n",
    "La covarianza è una misura utile per capire la relazione tra due serie, ma ha un limite: la covarianza non tiene conto della scala delle due serie. Ad esempio, se si misura il peso di una persona in chilogrammi e in libbre, la covarianza tra le due serie sarà influenzata dal fatto che un chilogrammo è circa 2,2 libbre. Per questo motivo, in molti casi si utilizza il coefficiente di correlazione di Pearson o di Spearman, che sono covarianza normalizzata rispettivamente dai valori di deviazione standard e di rank.\n",
    "\n",
    "La formula della covarianza utilizza la deviazione dalla media campionaria per calcolare quanto le due serie X e Y si discostano dalla loro media. La somma delle deviazioni è un'informazione importante, ma se si utilizza direttamente la somma delle deviazioni nella formula, il risultato ottenuto sarà influenzato dal numero di osservazioni presenti nella serie.\n",
    "\n",
    "Per evitare questo problema, nella formula della covarianza si divide la somma delle deviazioni per il numero di osservazioni meno uno, cioè $n-1$. Questa divisione normalizza la somma delle deviazioni, in modo che il risultato della covarianza dipenda solo dalla relazione tra le due serie, e non dal numero di osservazioni.\n",
    "\n",
    "`In pratica, dividere per n-1 invece di n rende la covarianza una stima più accurata della vera covarianza delle popolazioni da cui sono state estratte le due serie. Questo rende la covarianza un'indicatore più affidabile della relazione tra le due serie, soprattutto quando il numero di osservazioni è relativamente piccolo.`\n",
    "\n",
    "### Let's start introducing the Pearson's correlation coefficient:\n",
    "\n",
    "`The 1st way in which we can write it is the following:`\n",
    "\n",
    "$ \\rho_{X,Y}= \\frac{\\operatorname{cov}(X,Y)}{\\sigma_X \\sigma_Y}$\n",
    "\n",
    "where:\n",
    "* $ \\operatorname{cov} $ is the covariance of the two series that plot the coordinates of each point of a cloud of points\n",
    "* $ \\sigma_X $ is the standard deviation of $X $\n",
    "* $ \\sigma_Y $ is the standard deviation of  $ Y $\n",
    "\n",
    "The formula for $\\rho$ can be expressed in terms of mean and expectation.\n",
    "\n",
    "$$\\operatorname{cov}(X,Y) = \\mathbb{E}[(X-\\mu_X)(Y-\\mu_Y)]$$\n",
    "\n",
    "So Pearson correlation $\\rho$ can also be written as:\n",
    "\n",
    "$$\\rho_{X,Y}=\\frac{\\mathbb{E}[(X-\\mu_X)(Y-\\mu_Y)]}{\\sigma_X\\sigma_Y}$$\n",
    "\n",
    "\n",
    "\n",
    "- The correlation coefficient ranges between −1 and 1. \n",
    "- An absolute value of exactly $\\pm 1$ implies that a **linear equation describes the relationship between X and Y perfectly, with all data points lying on a line**. \n",
    "- The correlation **sign is determined by the regression slope**: a value of +1 implies that all data points lie on a line for which Y increases as X increases, and vice versa for −1.\n",
    "- `0` means that there is no linear dependency between variables\n",
    "\n",
    "$$\n",
    "r = \\frac{\\Sigma((X_i - \\bar{X})(Y_i - \\bar{Y}))}{\\sqrt{(\\Sigma((X_i - \\bar{X})^2 \\Sigma(Y_i - \\bar{Y})^2))}}\n",
    "$$\n",
    "\n",
    "- It takes maximum intensity when numerator is equal to denumerator. Otherwise Covariance is Always less than the product of the std. deviation\n",
    "- The **sign of the covariance** tells you if the data is **correlated** or **anticorrelated**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEARSON'S CORRELATION COEFFICIENT GEOMETRY:\n",
    "\n",
    "<img src=\"figs01/Geometry1.PNG\" style=\"width:30%\">\n",
    "<img src=\"figs01/Geometry2.PNG\" style=\"width:30%\">\n",
    "<img src=\"figs01/Geometry3.PNG\" style=\"width:30%\">\n",
    "<img src=\"figs01/Geometry4.PNG\" style=\"width:30%\">\n",
    "<img src=\"figs01/Geometry5.PNG\" style=\"width:30%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final note:  estimation $\\rightarrow$ Predictive power for future data\n",
    "\n",
    "<img src=\"figs01/Geometry6.PNG\" style=\"width:30%\">\n",
    "<img src=\"figs01/Geometry7.PNG\" style=\"width:30%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final note: more samples we have, the better we predict !\n",
    "\n",
    "<img src=\"figs01/Geometry8.PNG\" style=\"width:40%\">\n",
    "<img src=\"figs01/Geometry9.PNG\" style=\"width:40%\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDUCTIVE VS. DEDUCTIVE REASONING IN ML\n",
    "\n",
    "L'apprendimento induttivo e quello deduttivo sono due approcci fondamentali nell'apprendimento automatico (Machine Learning). Le principali differenze tra i due approcci sono le seguenti:\n",
    "\n",
    "`Approccio generale:` L'apprendimento induttivo è un approccio \"bottom-up\", che parte dai dati per estrarre una regola generale. L'apprendimento deduttivo è un approccio \"top-down\", che parte da una regola generale per applicarla a un insieme di dati specifici.\n",
    "\n",
    "`Sviluppo della conoscenza:` L'apprendimento induttivo sviluppa la conoscenza a partire dai dati osservati, identificando modelli o relazioni tra i dati stessi. L'apprendimento deduttivo si basa invece sulla conoscenza pregressa di regole o modelli che sono stati definiti in precedenza.\n",
    "\n",
    "`Flessibilità:` L'apprendimento induttivo è più flessibile rispetto all'apprendimento deduttivo, poiché è in grado di adattarsi a dati nuovi o inaspettati che possono essere incontrati durante il processo di apprendimento. L'apprendimento deduttivo, d'altra parte, è più rigido e richiede che i dati siano conformi alle regole o ai modelli predefiniti.\n",
    "\n",
    "`Complessità dei dati:` L'apprendimento induttivo è più adatto per modellare dati complessi e non lineari, mentre l'apprendimento deduttivo è più adatto per modellare dati strutturati e ben definiti.\n",
    "\n",
    "`Processo di apprendimento:` L'apprendimento induttivo richiede di esaminare una grande quantità di dati per identificare le relazioni e le tendenze tra di essi. L'apprendimento deduttivo richiede di definire le regole o i modelli prima di applicarli ai dati.\n",
    "\n",
    "In sintesi, l'apprendimento induttivo e quello deduttivo sono approcci complementari nell'apprendimento automatico, e la scelta dell'approccio più adatto dipende dalle caratteristiche del problema da risolvere e dei dati a disposizione.\n",
    "\n",
    "### INDUCTIVE LEARNING:\n",
    "\n",
    "<img src=\"figs01/19_supervised_example.PNG\" style=\"width:40%\">\n",
    "\n",
    "### TRANSDUCTIVE LEARNING:\n",
    "\n",
    "<img src=\"figs01/Transductive1.PNG\" style=\"width:20%\">\n",
    "<img src=\"figs01/Transductive2.PNG\" style=\"width:20%\">\n",
    "\n",
    "### LEARNING PARADIGMS\n",
    "\n",
    "### 1. Supervised learning (we have labels)\n",
    "\n",
    "Assume that there is a unknown and complex generator $\\mathcal{D}$ that provides output pairs $(\\mathbf{x},y)$.\n",
    "\n",
    "- We refer to this **unknown generator process as an unkown probability distribution** $\\mathcal{D}$ over input pairs  $(\\mathbf{x},y) \\in \\mathcal{X}\\times \\mathcal{Y}$.\n",
    "\n",
    "- **Example:** pairs of images and a label as in the case of bird/non-bird\n",
    "\n",
    "  - $\\mathbf{x}$ corresponds to the image; \n",
    "  - $y$ to the label.\n",
    "\n",
    "- Given paired $(\\mathbf{x},y)$, we learn to predict the label when given as input unseen data.\n",
    "\n",
    "  - **Classification: the output is a discrete value (category)**\n",
    "     - Binary classification (0/1)\n",
    "     - Multi-class classification (1...N)\n",
    "  - **Regression: the output is a continous value (real-valued output)**\n",
    "\n",
    "In pratice, in a real-world problem **no one has access to $\\mathcal{D}$ because problems are too complex.**\n",
    "\n",
    "> Try to write a computer program to generate all possible natural images that you can find in the word. Is it easy ?\n",
    "  \n",
    "Let's assume here that we have access to $\\mathcal{D}$ as a python function `get_prob_under_D(x,y)` that takes as input a pair `(x,y)` and returns the probability of the pair under $\\mathcal{D}$.\n",
    "\n",
    "If so, we can define the **Bayes optimal classifier** as the classifier that:\n",
    " - for any test input $\\mathbf{x}^{\\prime}$, simply returns the $y^{\\prime}$ that maximizes `get_prob_under_D(x,y)` \n",
    " - Or else, try all possible labels and return the label which yields maximum probability.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "h({x}^{\\prime}) = \\arg\\max_{y^{\\prime} \\in \\mathcal{Y} } \\mathcal{D}(x^{\\prime},y^{\\prime})\n",
    "\\end{equation}\n",
    "\n",
    "### 2. Unsupervised learning (we do NOT have labels)\n",
    "\n",
    "## TAKE AWAY\n",
    "The take-home message is that if someone gave us access to the \"data distribution\", forming an **optimal classifier would be trivial.**\n",
    "\n",
    "## REAL WORLD\n",
    "Unfortunately, no one gives us the implementation of this distribution.\n",
    "- We need to figure out ways of **learning the mapping from x to y**, given **only access to a training set sampled from $\\mathcal{D}$**, rather than $\\mathcal{D}$ itself.\n",
    "\n",
    "## TRAINING SET\n",
    "\n",
    "\\begin{equation}\n",
    " \\underbrace{\\{\\mathbf{x}_i,y_i\\}_{i=1}^N}_{\\text{known}} \\sim \\underbrace{\\mathcal{D}}_{\\text{unknown}}\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "- $N$ is the number of training samples\n",
    "- the vector $\\mathbf{x}$ is the input data\n",
    "- $y$ is the associated (scalar) label\n",
    "\n",
    "## SUPERVISED LEARNING FINAL DEFINITION\n",
    "\n",
    "**Goal:** given a training set with labels, learn a function over a set of possibile functions (hypothesis over a hypothesis set) \n",
    "\n",
    "$$h \\in \\mathcal{H}\\text{ so that }h : \\mathbf{x} \\mapsto y$$\n",
    "\n",
    "**Output of the learning is $h(\\cdot)$** that can be used to do prediction at test-time.\n",
    "\n",
    "**Prediction:** classification (discrete-valued) vs regression (real-valued output).\n",
    "\n",
    "<img src=\"figs01/09_ml_approach.PNG\" style=\"width:20%\">\n",
    "\n",
    "<img src=\"figs01/19_supervised_example.png\" style=\"width:40%\">\n",
    "\n",
    "## UNSUPERVISED LEARNING FINAL DEFINITION\n",
    "\n",
    "\\begin{equation}\n",
    " \\underbrace{\\{\\mathbf{x}_i\\}_{i=1}^N}_{\\text{known yet no labels}} \\sim \\underbrace{\\mathcal{D}}_{\\text{unknown}}\n",
    "\\end{equation}\n",
    "\n",
    "- We do not have any labels paired with the data.\n",
    "- Create an internal representation of the input, **capturing regularities/structure** in data.\n",
    " - Examples: **form clusters**, **extract features**.\n",
    " - How do we know if a representation is good ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLUSTERING (unsupervised)\n",
    "\n",
    "Il clustering è un algoritmo di apprendimento non supervisionato utilizzato in \"Machine Learning\" per raggruppare insiemi di oggetti o dati in base alle loro caratteristiche o similitudini.\n",
    "\n",
    "In pratica, il clustering cerca di identificare gruppi o cluster di dati simili tra loro, basandosi su misure di distanza o similarità tra le loro caratteristiche. Ad esempio, se si hanno dati relativi a diversi clienti di un'azienda, il clustering potrebbe identificare gruppi di clienti con comportamenti di acquisto simili, o gruppi di clienti che hanno interessi simili.\n",
    "\n",
    "L'obiettivo principale del clustering è quello di suddividere un insieme di dati in gruppi omogenei o cluster, in modo da poterli analizzare e comprendere meglio. Inoltre, il clustering può essere utilizzato per identificare anomalie o casi particolari che si discostano dai gruppi principali, permettendo di individuare eventuali problemi o opportunità.\n",
    "\n",
    "Esistono diversi algoritmi di clustering, come il k-means, il DBSCAN, il clustering gerarchico e molti altri, ognuno dei quali utilizza un approccio diverso per raggruppare i dati in base alle loro caratteristiche. Il clustering è ampiamente utilizzato in applicazioni di \"Machine Learning\", come l'analisi dei dati, il riconoscimento di pattern, l'elaborazione di immagini e molti altri campi.\n",
    "\n",
    "### EXAMPLE:\n",
    "\n",
    "- Each column is the result of a clustering algorithm.\n",
    "- The input data lives in a 2D space.\n",
    "- Colors indicates the clustering results (which points should be considered together).\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_001.png\" width=60% />\n",
    "\n",
    "<small>Image from [scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#clustering)</small>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRINCIPAL COMPONENTS ANALYSIS (PCA)\n",
    "\n",
    "I concetti di \"componenti principali\" e \"autovettori\" sono strettamente correlati in statistica e analisi dei dati.\n",
    "\n",
    "In analisi delle componenti principali (PCA), si cerca di ridurre la dimensionalità dei dati mantenendo la maggior parte possibile della loro varianza. Ciò viene fatto trasformando gli attributi originali in un nuovo insieme di variabili non correlate chiamate componenti principali. Queste componenti sono ordinate in modo tale che la prima componente spieghi la maggior parte possibile della varianza dei dati, la seconda spieghi il resto della varianza e così via.\n",
    "\n",
    "Le componenti principali sono calcolate come combinazione lineare degli attributi originali. Gli autovettori sono utilizzati per calcolare queste combinazioni lineari. Gli autovettori sono i vettori che soddisfano la seguente equazione: Ax = λx, dove A è una matrice quadrata, x è un vettore e λ è un numero. In altre parole, gli autovettori sono i vettori che quando moltiplicati per A danno come risultato un multiplo di se stessi.\n",
    "\n",
    "In PCA, la matrice di covarianza dei dati viene utilizzata come matrice A nella formula degli autovettori. Gli autovettori della matrice di covarianza rappresentano le direzioni principali di variazione dei dati e possono quindi essere utilizzati come base per calcolare le componenti principali. La prima componente principale corrisponde all'autovettore associato all'autovalore più grande, la seconda componente principale corrisponde all'autovettore associato al secondo autovalore più grande e così via.\n",
    "\n",
    "In sintesi, gli autovettori sono utilizzati in PCA per calcolare le combinazioni lineari delle variabili originali che massimizzano la varianza dei dati, dando origine alle componenti principali."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

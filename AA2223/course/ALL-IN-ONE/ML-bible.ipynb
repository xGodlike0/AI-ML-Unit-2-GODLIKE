{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # DATA CORRELATION\n",
    "\n",
    " Comprendere il concetto di correlazione tra dati è fondamentale in Machine Learning poiché la correlazione può influenzare direttamente la qualità dei modelli di Machine Learning e le decisioni basate su di essi.\n",
    "\n",
    "La correlazione tra dati si riferisce alla relazione tra due o più variabili in un dataset. Se due variabili sono correlate, significa che c'è una relazione tra di esse, e che il valore di una variabile può influenzare il valore dell'altra variabile.\n",
    "\n",
    "Quando si lavora con i dati di Machine Learning, la correlazione tra le variabili può influire sulla capacità del modello di fare previsioni accurate. Ad esempio, se due variabili sono fortemente correlate, può essere necessario considerarle entrambe quando si costruisce un modello. D'altra parte, se due variabili non sono correlate, può non essere necessario considerarle entrambe.\n",
    "\n",
    "Inoltre, la correlazione tra i dati può anche influire sulla scelta degli algoritmi di Machine Learning da utilizzare. Alcuni algoritmi funzionano meglio con dati altamente correlati, mentre altri funzionano meglio con dati poco correlati.\n",
    "\n",
    "In generale, comprendere la correlazione tra i dati è essenziale per garantire che i modelli di Machine Learning siano accurati e affidabili, e che le decisioni basate su di essi siano appropriate e ben informate.\n",
    "\n",
    " <img width=\"75%\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/1920px-Correlation_examples2.svg.png\" />\n",
    "\n",
    " <img src=\"https://wtmaths.com/P384_z1.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEASURING CORRELATION\n",
    "\n",
    "Esistono diversi modi per misurare la correlazione tra i dati, ma i due metodi più comuni sono il coefficiente di correlazione di Pearson e il coefficiente di correlazione di Spearman.\n",
    "\n",
    "Il coefficiente di correlazione di Pearson misura la relazione lineare tra due variabili continue. Il coefficiente può variare da -1 a 1, dove -1 rappresenta una forte correlazione negativa, 0 rappresenta l'assenza di correlazione e 1 rappresenta una forte correlazione positiva.\n",
    "\n",
    "Il coefficiente di correlazione di Spearman, d'altra parte, è utilizzato per misurare la relazione tra due variabili ordinali o continue non normali. Questo coefficiente utilizza invece il grado di classifica delle variabili in modo da trovare la relazione monotona tra due variabili. Il coefficiente di correlazione di Spearman può variare da -1 a 1, dove -1 rappresenta una forte correlazione negativa, 0 rappresenta l'assenza di correlazione e 1 rappresenta una forte correlazione positiva.\n",
    "\n",
    "Per entrambi i coefficienti, i valori vicini a 0 indicano una bassa correlazione, mentre i valori vicini a 1 o -1 indicano una forte correlazione.\n",
    "\n",
    "In generale, il coefficiente di correlazione di Pearson è utilizzato per variabili continue normalmente distribuite, mentre il coefficiente di correlazione di Spearman è utilizzato per variabili ordinali o continue non normali. Tuttavia, l'uso di un coefficiente di correlazione dipende dalle specifiche caratteristiche dei dati e delle variabili coinvolte.\n",
    "\n",
    "<img width='70%' src=\"https://upload.wikimedia.org/wikipedia/commons/3/34/Correlation_coefficient.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of coordinates matrix:\n",
    "\n",
    "| X \t| Y |\n",
    "| ----------- | ----------- |\n",
    "| 0.1 |\t45\n",
    "| 0.1 |\t65\n",
    "| 0.2 |\t28\n",
    "| 0.3 |\t76\n",
    "| 0.5 |\t55\n",
    "| 0.6 |\t48\n",
    "| 0.9 |\t64\n",
    "| 1.1 |\t41\n",
    "| 1.5 |\t30\n",
    "| 1.8 |\t52\n",
    "| 1.8 |\t75\n",
    "| 1.9 |\t35\n",
    "| 2.1 |\t42\n",
    "| 2.2 |\t65\n",
    "| 3.0 |\t30\n",
    "| 3.6 |\t71"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEARSON'S CORRELATION COEFFICIENT\n",
    "\n",
    "https://www.youtube.com/watch?v=xZ_z8KWkhXE&list=LL&index=6&t=1034s\n",
    "\n",
    "### Recall that:\n",
    "\n",
    "<mark style=\"background-color: yellow;\">La covarianza di due serie è una misura statistica che indica la relazione lineare tra le due serie. La covarianza è una misura della variabilità congiunta delle due serie: se le due serie variano insieme in modo simile, la covarianza sarà positiva; se invece variano in modo opposto, la covarianza sarà negativa; se non c'è alcuna relazione lineare tra le due serie, la covarianza sarà zero.</mark>.\n",
    "\n",
    "Formalmente, la covarianza tra due serie X e Y è data dalla seguente formula:\n",
    "\n",
    "$$\\operatorname{cov}(X,Y) = \\frac{\\sum\\limits_{i=1}^{n} (X_i - \\bar{X}) (Y_i - \\bar{Y})}{n-1}$$\n",
    "\n",
    "dove $X_i$ e $Y_i$ sono i valori osservati delle due serie, $\\bar{X}$ e $\\bar{Y}$ sono le loro medie campionarie e $n$ è il numero di osservazioni.\n",
    "\n",
    "Se la covarianza è positiva, significa che le due serie sono correlate positivamente: cioè, quando il valore di una serie aumenta, anche il valore dell'altra serie tende ad aumentare. Se la covarianza è negativa, significa che le due serie sono correlate negativamente: cioè, quando il valore di una serie aumenta, il valore dell'altra serie tende a diminuire. Se la covarianza è zero, significa che le due serie non sono correlate linearmente.\n",
    "\n",
    "La covarianza è una misura utile per capire la relazione tra due serie, ma ha un limite: la covarianza non tiene conto della scala delle due serie. Ad esempio, se si misura il peso di una persona in chilogrammi e in libbre, la covarianza tra le due serie sarà influenzata dal fatto che un chilogrammo è circa 2,2 libbre. Per questo motivo, in molti casi si utilizza il coefficiente di correlazione di Pearson o di Spearman, che sono covarianza normalizzata rispettivamente dai valori di deviazione standard e di rank.\n",
    "\n",
    "La formula della covarianza utilizza la deviazione dalla media campionaria per calcolare quanto le due serie X e Y si discostano dalla loro media. La somma delle deviazioni è un'informazione importante, ma se si utilizza direttamente la somma delle deviazioni nella formula, il risultato ottenuto sarà influenzato dal numero di osservazioni presenti nella serie.\n",
    "\n",
    "Per evitare questo problema, nella formula della covarianza si divide la somma delle deviazioni per il numero di osservazioni meno uno, cioè $n-1$. Questa divisione normalizza la somma delle deviazioni, in modo che il risultato della covarianza dipenda solo dalla relazione tra le due serie, e non dal numero di osservazioni.\n",
    "\n",
    "`In pratica, dividere per n-1 invece di n rende la covarianza una stima più accurata della vera covarianza delle popolazioni da cui sono state estratte le due serie. Questo rende la covarianza un'indicatore più affidabile della relazione tra le due serie, soprattutto quando il numero di osservazioni è relativamente piccolo.`\n",
    "\n",
    "### Let's start introducing the Pearson's correlation coefficient:\n",
    "\n",
    "`The 1st way in which we can write it is the following:`\n",
    "\n",
    "$ \\rho_{X,Y}= \\frac{\\operatorname{cov}(X,Y)}{\\sigma_X \\sigma_Y}$\n",
    "\n",
    "where:\n",
    "* $ \\operatorname{cov} $ is the covariance of the two series that plot the coordinates of each point of a cloud of points\n",
    "* $ \\sigma_X $ is the standard deviation of $X $\n",
    "* $ \\sigma_Y $ is the standard deviation of  $ Y $\n",
    "\n",
    "The formula for $\\rho$ can be expressed in terms of mean and expectation.\n",
    "\n",
    "$$\\operatorname{cov}(X,Y) = \\mathbb{E}[(X-\\mu_X)(Y-\\mu_Y)]$$\n",
    "\n",
    "So Pearson correlation $\\rho$ can also be written as:\n",
    "\n",
    "$$\\rho_{X,Y}=\\frac{\\mathbb{E}[(X-\\mu_X)(Y-\\mu_Y)]}{\\sigma_X\\sigma_Y}$$\n",
    "\n",
    "\n",
    "\n",
    "- The correlation coefficient ranges between −1 and 1. \n",
    "- An absolute value of exactly $\\pm 1$ implies that a **linear equation describes the relationship between X and Y perfectly, with all data points lying on a line**. \n",
    "- The correlation **sign is determined by the regression slope**: a value of +1 implies that all data points lie on a line for which Y increases as X increases, and vice versa for −1.\n",
    "- `0` means that there is no linear dependency between variables\n",
    "\n",
    "$$\n",
    "r = \\frac{\\Sigma((X_i - \\bar{X})(Y_i - \\bar{Y}))}{\\sqrt{(\\Sigma((X_i - \\bar{X})^2 \\Sigma(Y_i - \\bar{Y})^2))}}\n",
    "$$\n",
    "\n",
    "- It takes maximum intensity when numerator is equal to denumerator. Otherwise Covariance is Always less than the product of the std. deviation\n",
    "- The **sign of the covariance** tells you if the data is **correlated** or **anticorrelated**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEARSON'S CORRELATION COEFFICIENT GEOMETRY:\n",
    "\n",
    "<img src=\"figs01/Geometry1.PNG\" style=\"width:30%\">\n",
    "<img src=\"figs01/Geometry2.PNG\" style=\"width:30%\">\n",
    "<img src=\"figs01/Geometry3.PNG\" style=\"width:30%\">\n",
    "<img src=\"figs01/Geometry4.PNG\" style=\"width:30%\">\n",
    "<img src=\"figs01/Geometry5.PNG\" style=\"width:30%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final note:  estimation $\\rightarrow$ Predictive power for future data\n",
    "\n",
    "<img src=\"figs01/Geometry6.PNG\" style=\"width:30%\">\n",
    "<img src=\"figs01/Geometry7.PNG\" style=\"width:30%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final note: more samples we have, the better we predict !\n",
    "\n",
    "<img src=\"figs01/Geometry8.PNG\" style=\"width:40%\">\n",
    "<img src=\"figs01/Geometry9.PNG\" style=\"width:40%\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDUCTIVE VS. DEDUCTIVE REASONING IN ML\n",
    "\n",
    "L'apprendimento induttivo e quello deduttivo sono due approcci fondamentali nell'apprendimento automatico (Machine Learning). Le principali differenze tra i due approcci sono le seguenti:\n",
    "\n",
    "`Approccio generale:` L'apprendimento induttivo è un approccio \"bottom-up\", che parte dai dati per estrarre una regola generale. L'apprendimento deduttivo è un approccio \"top-down\", che parte da una regola generale per applicarla a un insieme di dati specifici.\n",
    "\n",
    "`Sviluppo della conoscenza:` L'apprendimento induttivo sviluppa la conoscenza a partire dai dati osservati, identificando modelli o relazioni tra i dati stessi. L'apprendimento deduttivo si basa invece sulla conoscenza pregressa di regole o modelli che sono stati definiti in precedenza.\n",
    "\n",
    "`Flessibilità:` L'apprendimento induttivo è più flessibile rispetto all'apprendimento deduttivo, poiché è in grado di adattarsi a dati nuovi o inaspettati che possono essere incontrati durante il processo di apprendimento. L'apprendimento deduttivo, d'altra parte, è più rigido e richiede che i dati siano conformi alle regole o ai modelli predefiniti.\n",
    "\n",
    "`Complessità dei dati:` L'apprendimento induttivo è più adatto per modellare dati complessi e non lineari, mentre l'apprendimento deduttivo è più adatto per modellare dati strutturati e ben definiti.\n",
    "\n",
    "`Processo di apprendimento:` L'apprendimento induttivo richiede di esaminare una grande quantità di dati per identificare le relazioni e le tendenze tra di essi. L'apprendimento deduttivo richiede di definire le regole o i modelli prima di applicarli ai dati.\n",
    "\n",
    "In sintesi, l'apprendimento induttivo e quello deduttivo sono approcci complementari nell'apprendimento automatico, e la scelta dell'approccio più adatto dipende dalle caratteristiche del problema da risolvere e dei dati a disposizione.\n",
    "\n",
    "### INDUCTIVE LEARNING:\n",
    "\n",
    "<img src=\"figs01/19_supervised_example.PNG\" style=\"width:40%\">\n",
    "\n",
    "### TRANSDUCTIVE LEARNING:\n",
    "\n",
    "<img src=\"figs01/Transductive1.PNG\" style=\"width:20%\">\n",
    "<img src=\"figs01/Transductive2.PNG\" style=\"width:20%\">\n",
    "\n",
    "### LEARNING PARADIGMS\n",
    "\n",
    "### 1. Supervised learning (we have labels)\n",
    "### 2. Unsupervised learning (we do NOT have labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRINCIPAL COMPONENTS ANALYSIS (PCA)\n",
    "\n",
    "I concetti di \"componenti principali\" e \"autovettori\" sono strettamente correlati in statistica e analisi dei dati.\n",
    "\n",
    "In analisi delle componenti principali (PCA), si cerca di ridurre la dimensionalità dei dati mantenendo la maggior parte possibile della loro varianza. Ciò viene fatto trasformando gli attributi originali in un nuovo insieme di variabili non correlate chiamate componenti principali. Queste componenti sono ordinate in modo tale che la prima componente spieghi la maggior parte possibile della varianza dei dati, la seconda spieghi il resto della varianza e così via.\n",
    "\n",
    "Le componenti principali sono calcolate come combinazione lineare degli attributi originali. Gli autovettori sono utilizzati per calcolare queste combinazioni lineari. Gli autovettori sono i vettori che soddisfano la seguente equazione: Ax = λx, dove A è una matrice quadrata, x è un vettore e λ è un numero. In altre parole, gli autovettori sono i vettori che quando moltiplicati per A danno come risultato un multiplo di se stessi.\n",
    "\n",
    "In PCA, la matrice di covarianza dei dati viene utilizzata come matrice A nella formula degli autovettori. Gli autovettori della matrice di covarianza rappresentano le direzioni principali di variazione dei dati e possono quindi essere utilizzati come base per calcolare le componenti principali. La prima componente principale corrisponde all'autovettore associato all'autovalore più grande, la seconda componente principale corrisponde all'autovettore associato al secondo autovalore più grande e così via.\n",
    "\n",
    "In sintesi, gli autovettori sono utilizzati in PCA per calcolare le combinazioni lineari delle variabili originali che massimizzano la varianza dei dati, dando origine alle componenti principali."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
